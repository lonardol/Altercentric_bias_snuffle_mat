---
title: "Power simulation for a binomial GLMM using parallelisation"
output: html_document
date: "2025-09-11"
---


```{r}
rm(list=ls())
library(cowplot)
library(gghalves)
library(ggthemes)
library(lme4)
library(kyotil)   # keepWarnings
library(parallel) # base R parallel
library(tidyverse)
library(here)
library(stringr)
```


```{r}
set.seed(1)

#-------------------------------------------------------
# Parameters
#-------------------------------------------------------

n.subject <- seq(from = 60, to = 180, by = 12)   # Sample sizes
n.blocks <- 3                                    # 3 blocks
conditions <- c("false_belief", "true_belief", "ignorance")

coop.breeds <- c(
  "appenzell_cattle_dog", "australian_cattle_dog", "australian_shepherd","austrian_pinscher","belgian_shepherd",
  "bernese_mountain_dog","bobtail","bohemian_shepherd_dog","border_collie",
  "bouvier_des_flandres","brittany_spaniel","bullmastiff","cocker_spaniel","collie","dalmatian","danish_swedish_farmdog","dutch_shepherd",
  "english_springer_spaniel","entlebucher_mountain_dog","flat_coated_retriever",
  "french_water_dog","german_longhaired_pointer","german_pinscher","german_shepherd",
  "german_short_haired_pointer","german_spitz", "german_wirehaired_pointer",
  "golden_retriever","great_swiss_mountain_dog","hovawart",
  "hungarian_shorthaired_pointer","irish_setter","italian_spinone",
  "kleiner_muensterlaender","labrador_retriever","miniature_american_shepherd",
  "miniature_pinscher","mudi","nova_scotia_duck_tolling_retriever","picardy_spaniel",
  "portuguese_water_dog","romagna_water_dog","rottweiler","schnauzer",
  "shetland_sheepdog","spanish_water_dog",
  "weimaraner","welsh_corgi","white_swiss_shepherd"
)

#-------------------------------------------------------
# Performance levels to run
#-------------------------------------------------------
fb_levels <- c(0.40)
tb_levels <- c(0.30)
ig_levels <- c(0.35, 0.20)

perf.grid <- expand.grid(
  fb = fb_levels,
  tb = tb_levels,
  ig = ig_levels,
  stringsAsFactors = FALSE
)

#-------------------------------------------------------
# Other parameters
#-------------------------------------------------------
logit <- function(p) log(p / (1 - p))

age.range <- 10:168
r.effects <- abs(logit(tb_levels)-logit(fb_levels))*2
r.slope.condition <- (abs(logit(tb_levels)-logit(fb_levels)))
r.slope.trial <- 0.1
n.simus <- 1000   # set back to 1000 in real analysis
all.res.all.samples <- data.frame()

contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))


# Extract p from drop1 
get_p <- function(tab, term) {
  if (is.null(tab)) return(NA_real_)
  rn <- rownames(tab)
  if (is.null(rn) || !(term %in% rn)) return(NA_real_)
  cn <- colnames(tab)
  tgt <- cn[cn %in% c("Pr(>Chi)", "Pr(>Chisq)", "Pr(Chi)")]
  if (length(tgt) == 0) return(NA_real_)
  as.numeric(tab[term, tgt[1]])
}

#-------------------------------------------------------
# Parallel cluster setup
#-------------------------------------------------------
n_cores <- max(1L, detectCores() - 1L)
cl <- makeCluster(n_cores, type = "PSOCK")
clusterEvalQ(cl, {
  library(lme4)
  library(kyotil)
})

#-------------------------------------------------------
# Main loops over sample size & performance levels
#-------------------------------------------------------
for (j in seq_along(n.subject)) {
  for (k in seq_len(nrow(perf.grid))) {
    
    fb.per <- perf.grid$fb[k]
    tb.per <- perf.grid$tb[k]
    ig.per <- perf.grid$ig[k]
    
    # Compute logits for these levels
    lp_FB_coop <- logit(fb.per)
    lp_TB_coop <- logit(tb.per)
    lp_IG_coop <- logit(ig.per)
    
    coefs <- c(
      "(Intercept)"          = lp_FB_coop,
      "conditiontrue_belief" = lp_TB_coop - lp_FB_coop,
      "conditionignorance"   = lp_IG_coop - lp_FB_coop,
      "sexM"                 = 0,
      "baited.fstgrey"       = 0,
      "z.age"                = -0.49,
      "z.trial"              = 0
    )
    
    #-------------------------------------------------------
    # Generate the start.data for this N and performance set
    #-------------------------------------------------------
    start.data <- data.frame()

    subj_ids <- paste("subj", str_pad(1:n.subject[j], 2, pad = "0"), sep = ".")
    
    for (subj in subj_ids) {
      # Assign between-subject variables
      sex_val <- sample(c("F", "M"), 1)
      baited_val <- sample(c("blue", "grey"), 1)  # between-subject
      age_val <- sample(age.range, 1)             # between-subject age
      
      # Generate 3 blocks, each containing one trial per condition in random order
      subj_trials <- lapply(1:n.blocks, function(b) {
        cond_order <- sample(conditions, length(conditions), replace = FALSE) # random order within block
        data.frame(
          subj.id    = subj,
          block      = b,
          trial      = (b - 1) * length(conditions) + 1:length(conditions),
          condition  = cond_order,
          sex        = sex_val,
          baited.fst = baited_val,
          age        = age_val,     # same age for all trials of this subject
          stringsAsFactors = FALSE
        )
      })
      
      subj_df <- do.call(rbind, subj_trials)
      start.data <- rbind(start.data, subj_df)
    }
    start.data$N <- n.subject[j]
    # Compute z.age after creating whole dataset
    start.data$z.age <- as.numeric(scale(start.data$age))
    start.data$z.trial <- as.numeric(scale(start.data$trial))
    # Factor encoding
    start.data$condition <- factor(start.data$condition, levels = conditions)
    start.data$sex        <- factor(start.data$sex, levels = c("F","M"))
    start.data$baited.fst <- factor(start.data$baited.fst, levels = c("blue","grey"))
    
    # Dummy codings for random slopes
    start.data$condition.dummy1   <- as.numeric(start.data$condition == "true_belief")
    start.data$condition.dummy2   <- as.numeric(start.data$condition == "ignorance")
    start.data$condition.dummy1.c <- start.data$condition.dummy1 - mean(start.data$condition.dummy1)
    start.data$condition.dummy2.c <- start.data$condition.dummy2 - mean(start.data$condition.dummy2)
    
    # Model matrix for LP
    m.mat <- model.matrix(~ condition + sex + baited.fst + z.age + z.trial, data = start.data)
    LP_fixed <- as.numeric(m.mat[, names(coefs), drop = FALSE] %*% coefs)
    
    # Export to workers
    clusterExport(cl, varlist = c("start.data","LP_fixed","r.effects","r.slope.condition", "r.slope.trial","contr","get_p","coop.breeds", "n.subject",
                                  "fb.per","tb.per","ig.per","coefs"),
                  envir = environment())
    
    clusterSetRNGStream(cl, iseed = 12345 + j + k)
    
    #-------------------------------------------------------
    # Simulation function
    #-------------------------------------------------------
    sim_fun <- function(i) {
      dat <- start.data
      #dat$breed <- as.factor(sample(x = coop.breeds, size = nrow(dat), replace = TRUE))
      nb <- nlevels(as.factor(dat$subj.id))
      b0 <- rnorm(nb, sd = r.effects)
      b1 <- rnorm(nb, sd = r.slope.condition)
      b2 <- rnorm(nb, sd = r.slope.condition)
      b3 <- rnorm(nb, sd = r.slope.trial)
      idx <- as.numeric(as.factor(dat$subj.id))
      LP <- LP_fixed + b0[idx] +
        b1[idx] * dat$condition.dummy1.c +
        b2[idx] * dat$condition.dummy2.c + 
        b3[idx] * dat$z.trial  
      dat$choice <- rbinom(n = nrow(dat), size = 1, prob = plogis(LP))
      
      full <- keepWarnings(glmer(
        choice ~ condition + sex + baited.fst + z.age +z.trial+
          (1 + condition.dummy1.c + condition.dummy2.c + z.trial || subj.id),
        family = binomial, data = dat, control = contr
      ))
      
      d1 <- tryCatch(as.data.frame(drop1(full$value, test = "Chisq")), error = function(e) NULL)
      
      means <- with(dat, tapply(choice, list(condition), mean))
      mc_fb_coop <- means["false_belief"]
      mc_tb_coop <- means["true_belief"]
      mc_ig_coop <- means["ignorance"]
      
      fe <- tryCatch(fixef(full$value), error = function(e) setNames(rep(NA_real_, length(coefs)), names(coefs)))
      re_sd <- tryCatch(as.data.frame(summary(full$value)$varcor)[1, "sdcor"], error = function(e) NA_real_)
      
      out <- list(
        N = unique(dat$N),
        fb_per = fb.per,
        tb_per = tb.per,
        ig_per = ig.per,
        icpt = fe["(Intercept)"],
        conditiontrue_belief = fe["conditiontrue_belief"],
        conditionignorance   = fe["conditionignorance"],
        sexM = fe["sexM"],
        baited.fstgrey = fe["baited.fstgrey"],
        z.age = fe["z.age"],
        z.trial = fe["z.trial"],
        warns.full = nchar(paste(full$warnings, collapse = "")),
        re.sd = re_sd,
        lrt.p.drop1.condition = get_p(d1, "condition"),
        lrt.p.drop1.sex = get_p(d1, "sex"),
        lrt.p.drop1.baited_fst = get_p(d1, "baited.fst"),
        lrt.p.drop1.z_age = get_p(d1, "z.age"),
        lrt.p.drop1.z_trial = get_p(d1, "z.trial"),
        mean_choice_fb_cooperative = as.numeric(mc_fb_coop),
        mean_choice_tb_cooperative = as.numeric(mc_tb_coop),
        mean_choice_ig_cooperative = as.numeric(mc_ig_coop)
      )
      out
    }
    
    res_list <- parLapply(cl, 1:n.simus, sim_fun)
    res_df <- as.data.frame(do.call(rbind, res_list))
    all.res.all.samples <- rbind(all.res.all.samples, res_df)
    
    message("Finished N = ", n.subject[j], 
            " FB=", fb.per, " TB=", tb.per, " IG=", ig.per)
  }
}

stopCluster(cl)

# Save results
save.image(file = here("power_analysis", "power_sim_snuffle_mat_workspace_parallel_10_percent.RData"))
```

Notes on changes
- Efficiency:
  - z.age is computed once per sample size, not recomputed each simulation.
  - Factor levels and centered dummies are computed once per sample size.
  - The model matrix and the fixed-effects linear predictor (LP_fixed) are computed once per sample size.
  - In each simulation we only sample breed, draw random effects, simulate choice, and fit the same two models.
  - Cell means are computed via tapply instead of a grouped dplyr pipeline.

- Parallelisation:
  - Uses base parallel::parLapply over simulations within each sample size (outer loop over n.subject retained).
  - Workers load lme4 and kyotil, and receive required objects via clusterExport.
  - RNG is reproducible via clusterSetRNGStream(cl, iseed = 12345 + j).


##Evaluation

```{r}
load(file = here("power_analysis", "power_sim_snuffle_mat_workspace_parallel_10_percent.RData"))
```

```{r}
all.res <- data.frame(
  lapply(all.res.all.samples, function(col) {
    if (is.list(col) && all(sapply(col, length) <= 1)) {
      suppressWarnings(as.numeric(unlist(col)))
    } else {
      col
    }
  }),
  stringsAsFactors = FALSE
)



# tidy data frame (often more convenient than a 3D array)
warn_table_df <- all.res %>%
  mutate(warn = as.integer(warns.full > 0)) %>%
  group_by(N, fb_per, tb_per, ig_per) %>%
  summarise(n.warns = sum(warn), .groups = "drop")



```
Converged-only subset


```{r}


all.res2 <- all.res %>% filter(warns.full == 0) #

#How many models converged and power summaries

n.converged <- all.res2 %>%
  group_by(N, fb_per, tb_per, ig_per) %>%
  summarise(n.converged = n(), .groups = "drop")


lrt.data2 <- all.res2 %>%
  dplyr::ungroup() %>% 
  dplyr::group_by(N, fb_per, tb_per, ig_per) %>% 
  dplyr::summarise(

    # main effect of condition <from drop1
    lrt.p.condition.median = median(lrt.p.drop1.condition, na.rm = TRUE),
    n.sign.lrt.condition   = sum(lrt.p.drop1.condition < 0.05, na.rm = TRUE),
    proportion.sign.lrt.condition = n.sign.lrt.condition / n.simus,

    mean_choice_fb_cooperative    = mean(mean_choice_fb_cooperative, na.rm = TRUE),
    mean_choice_tb_cooperative    = mean(mean_choice_tb_cooperative, na.rm = TRUE),
    mean_choice_ig_cooperative    = mean(mean_choice_ig_cooperative, na.rm = TRUE),

    .groups = "drop"
  )


lrt.data2
#save.image("power_sim_snuffle_mat_10_percent_eval.RData")


```


Notes on efficiency
- The warnings are summarized once using mutate + summarise, avoiding repeated indexing and avoiding a separate n.converged join later.
- All summary metrics are computed in a single summarise call over the grouped data, eliminating the need for a separate n.converged table and full_join.
- Using na.rm = TRUE in summaries ensures robustness if any p-values are missing.
- If you prefer your “power” to reflect only converged models, replace the denominator by n.converged instead of n.simus:
  proportion.sign.lrt.fullnull = n.sign.lrt.fullnull / n.converged
  proportion.sign.lrt.int = n.sign.lrt.int / n.converged
  Plotting: power vs total sample size
```{r}
library(ggplot2)

plot.sample.sizes.power.snuffle.mat <- ggplot(lrt.data2,
                                              aes(x = factor(N), y = proportion.sign.lrt.condition * 100)) +
  geom_col() +
  ylab("Power (% significant LRT for condition)") +
  xlab("Total sample size") + scale_x_discrete() + geom_hline(
    yintercept = 80,
    col = "blue",
    lty = 2,
    lwd = 0.9
  ) + theme_classic() + facet_wrap(~ig_per)

ggsave(plot.sample.sizes.power.snuffle.mat, filename = "./plots/sample_sizes_power_analysis_snuffle_mat_10_percent.png", scale = 0.55, height = 6, width = 15)
```


Condition means (averaged across breed types), by sample size

```{r}
library(tidyr)

cond_means_bt <- lrt.data2 %>% select(
  n.subject,
  mean_choice_fb_cooperative,
  mean_choice_tb_cooperative,
  #mean_choice_knctr_cooperative,
 # mean_choice_fb_independent,
  #mean_choice_tb_independent,
 # mean_choice_knctr_independent
) %>% pivot_longer(-n.subject, names_to = "name", values_to = "mean_choice") %>% mutate(
 # breed_type = ifelse(grepl("cooperative$", name), "cooperative", "independent"),
  condition = case_when(
    grepl("fb", name) ~ "fb",
    grepl("tb", name) ~ "tb",
  #  grepl("knctr", name) ~ "control",
    TRUE ~ NA_character_
  )
)


ggplot(cond_means_bt,
       aes(x = condition, y = mean_choice, fill = condition)) +
  geom_col(position = position_dodge(width = 0.8), color = "black") +
  facet_wrap(~ n.subject) + theme_classic() + labs(y = "Mean choice", x = "Condition", fill = "Condition")

ggsave(last_plot(),
       filename = "plots/mean_choices.png",
       scale = 0.55, height = 12, width = 16)
```



Proportion of significant LRTs for condition (converged models only)

```{r}
# If  r.effect and/or r.slope.condition vary, facet by them; if not, this reduces to bars by N
p.int.power <- ggplot(lrt.data2, aes(x = factor(n.subject), y = proportion.sign.condition)) +
  geom_col(color = "black", fill = "dodgerblue") +
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  geom_hline(yintercept = 0.8, colour = "black", lwd = 1, lty = 2) +
  labs(y = "Power (proportion significant LRT for condition)",
       x = "Total sample size (N)") +
  theme_bw() +
  facet_grid(r.slope.condition ~ r.effect, labeller = label_both)

p.int.power

ggsave(p.int.power,
       filename = "plots/differentNs_power.png",
       scale = 0.55, height = 12, width = 16)
```



